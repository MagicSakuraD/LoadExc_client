// main.rs

use anyhow::{anyhow, Context, Result};
use dotenvy::dotenv;
use livekit::prelude::*;
use livekit::options::TrackPublishOptions;
use livekit::webrtc::video_frame::{VideoFrame, VideoRotation, I420Buffer};
use livekit::webrtc::video_source::{RtcVideoSource, native::NativeVideoSource};
use std::env;
use std::path::Path;
use std::sync::Arc;
use tokio::sync::mpsc;
use tracing::{info, warn, error};
use tracing_subscriber::EnvFilter;

// GStreamer crates
use gstreamer as gst;
use gstreamer::prelude::*; // Trait extensions for GStreamer elements
use gstreamer_app as gst_app;
use gstreamer_app::prelude::*; // Trait extensions for AppSink
use gstreamer_video as gst_video;

// å…¨å±€è§†é¢‘æºï¼Œç”¨äºä» GStreamer çº¿ç¨‹å®‰å…¨åœ°æ¨é€è§†é¢‘å¸§
static GLOBAL_VIDEO_SOURCE: std::sync::OnceLock<Arc<RtcVideoSource>> = std::sync::OnceLock::new();

// å®šä¹‰ä¸€ä¸ªç»Ÿä¸€çš„å¸§æ¶ˆæ¯ï¼Œä»¥ä¾¿æœªæ¥æ‰©å±•ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœä¹Ÿéœ€è¦å¤„ç† RGBAï¼‰
enum FrameMsg {
    I420 {
        y: Vec<u8>,
        u: Vec<u8>,
        v: Vec<u8>,
        width: u32,
        height: u32,
        ts_us: i64,
    },
}

/// è®¾ç½®å¹¶å¯åŠ¨ GStreamer ç®¡é“
/// è¿™ä¸ªå‡½æ•°ä¼šå¤„ç†æ‰€æœ‰ GStreamer ç›¸å…³çš„åˆå§‹åŒ–å·¥ä½œ
fn setup_gstreamer_pipeline(tx: mpsc::Sender<FrameMsg>) -> Result<gst::Pipeline> {
    println!("ğŸ¬ å¯åŠ¨ GStreamer æ–‡ä»¶è§£ç ...");
    gst::init().context("Failed to initialize GStreamer")?;

    let video_path = env::var("VIDEO_FILE").unwrap_or_else(|_| "video/test.mp4".to_string());
    println!("   ğŸ“„ è¾“å…¥æ–‡ä»¶: {}", &video_path);
    if !Path::new(&video_path).exists() {
        anyhow::bail!("âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥ VIDEO_FILE è·¯å¾„: {}", video_path);
    }
    
    let loop_video = env::var("LOOP_VIDEO").unwrap_or_else(|_| "true".to_string()).parse::<bool>().unwrap_or(true);
    println!("   ğŸ”„ å¾ªç¯æ’­æ”¾: {}", if loop_video { "å¯ç”¨" } else { "ç¦ç”¨" });

    // æ„å»º GStreamer ç®¡é“æè¿°å­—ç¬¦ä¸²
    // filesrc -> decodebin -> videoconvert -> video/x-raw,format=I420 -> appsink
    let fps: u32 = env::var("VIDEO_FPS").ok().and_then(|v| v.parse().ok()).unwrap_or(30);
    let pipeline_desc = format!(
        "filesrc location=\"{}\" ! decodebin ! videoconvert ! videorate ! video/x-raw,format=I420,framerate={}/1 ! appsink name=sink emit-signals=true sync=true max-buffers=2 drop=true",
        video_path, fps
    );
    println!("   âš™ï¸  GStreamer Pipeline: {}", pipeline_desc);

    let pipeline = gst::parse::launch(&pipeline_desc)
        .context("Failed to build GStreamer pipeline from description")?;
    
    let pipeline = pipeline
        .dynamic_cast::<gst::Pipeline>()
        .map_err(|_| anyhow!("Failed to cast GstElement to GstPipeline"))?;

    let sink = pipeline
        .by_name("sink")
        .ok_or_else(|| anyhow!("Could not find element 'sink' in the pipeline"))?
        .dynamic_cast::<gst_app::AppSink>()
        .map_err(|_| anyhow!("Sink element is not an AppSink"))?;

    // è®¾ç½® AppSink çš„å±æ€§ä¸å›è°ƒå‡½æ•°ï¼Œå½“æœ‰æ–°å¸§å¯ç”¨æ—¶ï¼ŒGStreamer ä¼šè°ƒç”¨è¿™ä¸ªé—­åŒ…
    sink.set_property("sync", &true);
    sink.set_callbacks(
        gst_app::AppSinkCallbacks::builder()
            .new_sample(move |appsink| {
                let sample = appsink.pull_sample().map_err(|_| {
                    warn!("Could not pull sample from appsink");
                    gst::FlowError::Eos
                })?;

                let buffer = sample.buffer().ok_or_else(|| {
                    warn!("GStreamer sample did not contain a buffer");
                    gst::FlowError::Error
                })?;
                
                let info = sample.caps()
                    .and_then(|c| gst_video::VideoInfo::from_caps(c).ok())
                    .ok_or_else(|| {
                        warn!("GStreamer sample caps did not contain video info");
                        gst::FlowError::Error
                    })?;

                // ä» buffer ä¸­æå– I420 çš„ Y, U, V ä¸‰ä¸ªå¹³é¢
                let map = gst_video::VideoFrameRef::from_buffer_ref_readable(buffer, &info)
                    .map_err(|_| {
                        warn!("Failed to map GStreamer buffer as video frame");
                        gst::FlowError::Error
                    })?;
                
                let y = map.plane_data(0).unwrap_or_default().to_vec();
                let u = map.plane_data(1).unwrap_or_default().to_vec();
                let v = map.plane_data(2).unwrap_or_default().to_vec();
                
                // ä½¿ç”¨ç³»ç»Ÿæ—¶é—´ä½œä¸ºæ—¶é—´æˆ³ï¼Œä¿è¯æŒ‰å®æ—¶èŠ‚å¥æ¨é€
                let ts_us = {
                    use std::time::{SystemTime, UNIX_EPOCH};
                    let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap();
                    now.as_micros() as i64
                };

                // é€šè¿‡é€šé“å°†å¸§æ•°æ®å‘é€åˆ°ä¸» Tokio å¾ªç¯
                let _ = tx.try_send(FrameMsg::I420 {
                    y, u, v,
                    width: info.width(),
                    height: info.height(),
                    ts_us,
                });

                Ok(gst::FlowSuccess::Ok)
            })
            .build(),
    );

    // ã€é‡è¦ã€‘è®¾ç½® GStreamer æ¶ˆæ¯æ€»çº¿ç›‘å¬ï¼Œä»¥å®ç°å¥å£®çš„å¾ªç¯æ’­æ”¾
    if loop_video {
        let bus = pipeline.bus().context("Failed to get pipeline bus")?;
        let pipeline_weak = pipeline.downgrade(); // ä½¿ç”¨å¼±å¼•ç”¨ä»¥é¿å…å¾ªç¯å¼•ç”¨

        // åœ¨ä¸€ä¸ªå•ç‹¬çš„çº¿ç¨‹ä¸­ç›‘å¬æ€»çº¿æ¶ˆæ¯ï¼Œä¸ä¼šé˜»å¡ä¸»å¾ªç¯
        std::thread::spawn(move || {
            for msg in bus.iter_timed(gst::ClockTime::NONE) {
                // ä»…åœ¨ pipeline ä»ç„¶å­˜åœ¨æ—¶å¤„ç†æ¶ˆæ¯
                if let Some(pipeline) = pipeline_weak.upgrade() {
                    match msg.view() {
                        // å½“æ”¶åˆ° EOS (End-of-Stream) æ¶ˆæ¯æ—¶...
                        gst::MessageView::Eos(_) => {
                            info!("GStreamer EOS received, seeking to beginning for loop.");
                            // å°†æ’­æ”¾ä½ç½®é‡ç½®åˆ°å¼€å¤´ï¼Œå®ç°æ— ç¼å¾ªç¯
                            if let Err(e) = pipeline.seek_simple(gst::SeekFlags::FLUSH, gst::ClockTime::ZERO) {
                                warn!("Failed to seek pipeline to the beginning: {:?}", e);
                            }
                        }
                        gst::MessageView::Error(err) => {
                            error!(
                                "Error from GStreamer pipeline: {}, debug: {}",
                                err.error(),
                                err.debug().unwrap_or_else(|| "No debug info".into())
                            );
                            break; // å‡ºç°é”™è¯¯æ—¶é€€å‡ºç›‘å¬çº¿ç¨‹
                        }
                        _ => {}
                    }
                } else {
                    break; // å¦‚æœ pipeline è¢«é”€æ¯ï¼Œåˆ™é€€å‡ºçº¿ç¨‹
                }
            }
        });
    }

    Ok(pipeline)
}

/// å°†å·²æ˜¯ I420 æ ¼å¼çš„å¸§å¹³é¢æ•°æ®æ¨é€åˆ° LiveKit
async fn push_i420_planes(
    y_plane: &[u8],
    u_plane: &[u8],
    v_plane: &[u8],
    width: u32,
    height: u32,
    timestamp_us: i64,
) -> Result<()> {
    let Some(source) = GLOBAL_VIDEO_SOURCE.get() else {
        warn!("VideoSource not available, dropping frame");
        return Ok(());
    };

    let mut buffer = I420Buffer::new(width, height);
    let (y_data, u_data, v_data) = buffer.data_mut();
    
    // ç¡®ä¿æˆ‘ä»¬çš„æ•°æ®èƒ½å¤Ÿæ”¾å…¥ LiveKit çš„ buffer ä¸­
    if y_data.len() == y_plane.len() && u_data.len() == u_plane.len() && v_data.len() == v_plane.len() {
        y_data.copy_from_slice(y_plane);
        u_data.copy_from_slice(u_plane);
        v_data.copy_from_slice(v_plane);
    } else {
        warn!("Plane data size mismatch, dropping frame");
        return Ok(());
    }

    let frame = VideoFrame {
        rotation: VideoRotation::VideoRotation0,
        timestamp_us,
        buffer,
    };

    if let RtcVideoSource::Native(native_source) = &**source {
        native_source.capture_frame(&frame);
    } else {
        warn!("Unsupported video source type");
    }

    Ok(())
}

#[tokio::main]
async fn main() -> Result<()> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt()
        .with_env_filter(EnvFilter::from_default_env())
        .init();

    info!("Starting LoadExc_client");
    println!("ğŸš€ LoadExc_client å¯åŠ¨ä¸­...");
    println!("ğŸ“‹ ç¯å¢ƒå˜é‡æ£€æŸ¥:");

    // ä¼˜å…ˆä½¿ç”¨ .env ä¸­çš„é…ç½®ï¼ˆè¦†ç›–å·²å­˜åœ¨çš„ç¯å¢ƒå˜é‡ï¼‰
    let _ = dotenvy::dotenv_override().ok();

    // è¯»å– LiveKit è¿æ¥å‚æ•°
    let lk_url = env::var("LIVEKIT_URL").context("ç¯å¢ƒå˜é‡ LIVEKIT_URL æœªè®¾ç½®")?;
    let lk_token = env::var("LIVEKIT_TOKEN").context("ç¯å¢ƒå˜é‡ LIVEKIT_TOKEN æœªè®¾ç½®")?;

    println!("   âœ… LIVEKIT_URL: {}", lk_url);
    println!("   âœ… LIVEKIT_TOKEN: [hidden]");

    // --- LiveKit è¿æ¥å’Œè½¨é“åˆ›å»º ---
    println!("ğŸ”— æ­£åœ¨è¿æ¥åˆ° LiveKit æˆ¿é—´...");
    let (room, mut room_events) = Room::connect(&lk_url, &lk_token, RoomOptions::default())
        .await
        .context("è¿æ¥åˆ° LiveKit å¤±è´¥")?;
    info!("Connected to room: '{}'", room.name());
    println!("   âœ… æˆåŠŸè¿æ¥åˆ°æˆ¿é—´: '{}'", room.name());

    println!("ğŸ¥ åˆ›å»ºå¹¶å‘å¸ƒè§†é¢‘è½¨é“...");
    let track_name = env::var("VIDEO_TRACK_NAME").unwrap_or_else(|_| "gstreamer_feed".to_string());
    let native_source = NativeVideoSource::default();
    let source = RtcVideoSource::Native(native_source);
    let local_track = LocalVideoTrack::create_video_track(&track_name, source.clone());
    
    room.local_participant()
        .publish_track(
            LocalTrack::Video(local_track.clone()),
            TrackPublishOptions { source: TrackSource::Camera, ..Default::default() }
        )
        .await
        .context("å‘å¸ƒè§†é¢‘è½¨é“å¤±è´¥")?;
    
    info!(track = %track_name, "Published local video track");
    println!("   âœ… è§†é¢‘è½¨é“ '{}' å‘å¸ƒæˆåŠŸ", track_name);
    let _ = GLOBAL_VIDEO_SOURCE.set(Arc::new(source));

    // --- GStreamer è®¾ç½® ---
    let (tx, mut rx) = mpsc::channel::<FrameMsg>(4); // åˆ›å»ºé€šé“ï¼Œå®¹é‡ä¸º 4
    let pipeline = setup_gstreamer_pipeline(tx)?;

    // å¯åŠ¨ GStreamer ç®¡é“
    pipeline.set_state(gst::State::Playing)
        .context("æ— æ³•å°† GStreamer ç®¡é“è®¾ç½®ä¸º Playing çŠ¶æ€")?;
    println!("   âœ… GStreamer ç®¡é“å·²å¯åŠ¨");


    // --- ä¸»äº‹ä»¶å¾ªç¯ ---
    println!("ğŸ”„ è¿›å…¥ä¸»äº‹ä»¶å¾ªç¯ (æŒ‰ Ctrl+C åœæ­¢)");
    let mut frame_count = 0;
    loop {
        tokio::select! {
            // ç›‘å¬ LiveKit æˆ¿é—´äº‹ä»¶
            Some(event) = room_events.recv() => {
                info!(?event, "Received room event");
                if let RoomEvent::Disconnected { .. } = event {
                    println!("   âŒ æˆ¿é—´è¿æ¥å·²æ–­å¼€ï¼Œç¨‹åºå³å°†é€€å‡ºã€‚");
                    break;
                }
            }
            // ç›‘å¬ä» GStreamer ä¼ æ¥çš„æ–°è§†é¢‘å¸§
            Some(msg) = rx.recv() => {
                frame_count += 1;
                match msg {
                    FrameMsg::I420 { y, u, v, width, height, ts_us } => {
                        if frame_count % 100 == 0 { // æ¯ 100 å¸§æ‰“å°ä¸€æ¬¡æ—¥å¿—ï¼Œé¿å…åˆ·å±
                             println!("   ğŸ¬ æ­£åœ¨å¤„ç†ç¬¬ {} å¸§: {}x{}", frame_count, width, height);
                        }
                       
                        if let Err(e) = push_i420_planes(&y, &u, &v, width, height, ts_us).await {
                            warn!("Failed to push frame to LiveKit: {:?}", e);
                        }
                    }
                }
            }
            // ç›‘å¬ Ctrl+C ä¿¡å·ä»¥ä¼˜é›…åœ°å…³é—­
            _ = tokio::signal::ctrl_c() => {
                info!("Ctrl+C received, shutting down.");
                println!("\nğŸ›‘ æ”¶åˆ° Ctrl+C ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...");
                break;
            }
        }
    }

    // --- ä¼˜é›…åœ°å…³é—­ ---
    println!("ğŸ”„ æ­£åœ¨å…³é—­è¿æ¥å’Œç®¡é“...");
    
    // åœæ­¢ GStreamer ç®¡é“
    if let Err(e) = pipeline.set_state(gst::State::Null) {
        warn!("Failed to set pipeline to Null state: {}", e);
    }
    
    // å…³é—­ LiveKit æˆ¿é—´è¿æ¥
    room.close().await?;
    
    println!("âœ… ç¨‹åºæ­£å¸¸é€€å‡º");
    Ok(())
}